{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  OCR 이미지 문자인식 + 데이터 다운로드 + 데이터 손질"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. training data 다운 받기\n",
    "\n",
    "    MINIST(= 손글씨 트레이닝 데이터로 유명한 곳)\n",
    "       \n",
    "       http://yann.lecun.com/exdb/mnist\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) 파일의 path와 local 의 path 지정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "import gzip, os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 't10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 다운 받을 4개의 파일이름과 위치를 crawling 해오자!\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = requests.get(baseurl).text\n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "\n",
    "files_1 = []\n",
    "\n",
    "for tag in soup.select(\"p tt a\"):\n",
    "    files_1.append(tag[\"href\"])\n",
    "files_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### local path 지정중 default dir 이후의 path를 지정해 줄떄 꼭 \".\"을 붙인다 \n",
    "###### 붙이지 않으면 mkdir 명령어가 작동하지 않는다.\n",
    "savepath = \"./mnist\"\n",
    "baseurl = \"http://yann.lecun.com/exdb/mnist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) 파일 다운로드 받기 \n",
    "    with import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz \n",
      " local_path : ./mnist/train-images-idx3-ubyte.gz\n",
      "download: http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz \n",
      " local_path : ./mnist/train-labels-idx1-ubyte.gz\n",
      "download: http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \n",
      " local_path : ./mnist/t10k-images-idx3-ubyte.gz\n",
      "download: http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz \n",
      " local_path : ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# local에 data를 다운로드 받을 파일을 만드는것\n",
    "if not os.path.exists(savepath): os.mkdir(savepath)\n",
    "\n",
    "for path in files_1:\n",
    "    url_path = baseurl + \"/\" + path\n",
    "    local_path = savepath + \"/\" + path\n",
    "    print(\"download:\",url_path,\"\\n local_path :\",local_path)\n",
    "    if not os.path.exists(local_path):\n",
    "        req.urlretrieve(url_path,local_path)\n",
    "   #### 난 결과가 당연히 4개의 파일이 다른 파일안에 저장될줄 알았는대 한파일에 저장이 되었다.\n",
    "    ## 그렇다면 req.urlretrieve의 parameter 중 굳이 local_path를 지정한 이유가 무었일까?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1_3) Gzip 파일 압축해재 하기\n",
    "\n",
    "    with)import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gz_files : ./mnist/train-images-idx3-ubyte.gz \n",
      "raw_files : ./mnist/train-images-idx3-ubyte\n",
      "gz_files : ./mnist/train-labels-idx1-ubyte.gz \n",
      "raw_files : ./mnist/train-labels-idx1-ubyte\n",
      "gz_files : ./mnist/t10k-images-idx3-ubyte.gz \n",
      "raw_files : ./mnist/t10k-images-idx3-ubyte\n",
      "gz_files : ./mnist/t10k-labels-idx1-ubyte.gz \n",
      "raw_files : ./mnist/t10k-labels-idx1-ubyte\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "for path in files_1:\n",
    "    gz_files = savepath + \"/\" + path\n",
    "    raw_files = savepath + \"/\" + path.replace(\".gz\",\"\") ### 압축해재 하는 파일의 확장자는 .gz 이고 그곳의 데이터를 어떤 방식으로 저장할 것인가는 자신의 선택이다!!! \n",
    "    ### 및에는 만약에 압축파일이 jpg 사진으로 저장하고 싶을때 하는 명령어이다!\n",
    "    #raw_files = savepath + \"/\" + path.replace(\".gz\",\"jpg\")\n",
    " \n",
    "    print(\"gz_files :\",gz_files,\"\\nraw_files :\",raw_files)\n",
    "    ### 여기서 부터가 핵심이다.!\n",
    "        ### rb 읽기 전용으로 파일을 불러오고, 파일을 읽는다\n",
    "            ## 그후에 읽을 데이터를 새로운 파일에다 저장한다.\n",
    "    \n",
    "    with gzip.open(gz_files, \"rb\") as gz:\n",
    "        body = gz.read()\n",
    "        with open(raw_files, \"wb\") as w:\n",
    "            w.write(body)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 형식 바꾸기 (binary type -> csv type)\n",
    "\n",
    "    with) import struct (= binary 데이터를 처리하기위한 툴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2_1) 변환해주는 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_csv(name, maxdata):\n",
    "    # 1. 파일읽기\n",
    "    label_f = open(\"./mnist/\"+name+\"-labels-idx1-ubyte\",\"br\")\n",
    "    img_f = open(\"./mnist/\" +name+ \"-images-idx3-ubyte\",\"br\")\n",
    "    csv_f = open(\"./mnist/\" +name+ \".csv\",\"w\",encoding = \"utf-8\")\n",
    "    \n",
    "    # 2. header 정보 읽기\n",
    "    mag, label_count = struct.unpack(\">II\",label_f.read(8))\n",
    "    mag, img_count = struct.unpack(\">II\",img_f.read(8))\n",
    "    rows, cols = struct.unpack(\">II\", img_f.read(8))\n",
    "    pixels = rows * cols\n",
    "    \n",
    "    # 3. 데이터를 읽고 csv 로 저장하기!\n",
    "    res =[]\n",
    "    for idx in range(label_count):\n",
    "        if idx > maxdata:\n",
    "            break\n",
    "        label = struct.unpack(\"B\",label_f.read(1))[0]\n",
    "        bdata = img_f.read(pixels)\n",
    "        sdata = list(map(lambda n :str(n), bdata))\n",
    "        csv_f.write(str(label)+',')\n",
    "        csv_f.write(\",\".join(sdata)+\"\\r\\n\")\n",
    "        \n",
    "    # 4. 잘 저장 되었는지 확인을 위해서\n",
    "        if idx < 10:\n",
    "            s = \"P2 28 28 255\\n\"\n",
    "            s += \" \".join(sdata)\n",
    "            iname = \"./mnist/{0}-{1}-{2}.pgm\".format(name,idx,label)\n",
    "            #iname = \"./mnist/{0}-{1}-{2}.img\".format(name,idx,label)\n",
    "            ## img 데이터셋으로 하면 이미지가 손상된다.\n",
    "            with open(iname, \"w\", encoding = \"utf-8\") as f:\n",
    "                f.write(s)\n",
    "    csv_f.close()\n",
    "    label_f.close()\n",
    "    img_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2_2) 결과 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(\"train\", 1000)\n",
    "to_csv(\"t10k\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
